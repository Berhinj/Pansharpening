{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img, drop = None):\n",
    "    img_ravel = img.ravel()\n",
    "    if drop != None:\n",
    "        img_ravel = img_ravel[img_ravel!=drop]\n",
    "    plt.hist(img_ravel, bins=100)\n",
    "    plt.show()\n",
    "    \n",
    "def enhance(img, brightness, contrast):\n",
    "    IINFO = np.iinfo(img.dtype)\n",
    "\n",
    "    if brightness != 0:\n",
    "        brightness = np.floor((IINFO.max-IINFO.min)*brightness)\n",
    "\n",
    "        alpha = (IINFO.max - np.abs(brightness)) / IINFO.max\n",
    "        gamma = np.max(brightness, 0)\n",
    "\n",
    "        img = img.copy()*alpha + gamma\n",
    "        img[img>255] = 255\n",
    "        img[img<0] = 0\n",
    "        img = img.astype(IINFO.dtype)\n",
    "\n",
    "    if contrast != 0:\n",
    "        contrast = np.floor((IINFO.max-IINFO.min)*contrast)\n",
    "\n",
    "        HALF = np.floor((IINFO.max+IINFO.min)/2)\n",
    "        HALF_1 = HALF + 1\n",
    "\n",
    "        f = HALF_1*(contrast+HALF)/(HALF_1-contrast)\n",
    "        alpha = f/HALF\n",
    "        gamma = HALF - f\n",
    "\n",
    "        img = img.copy()*alpha + gamma\n",
    "        img[img>255] = 255\n",
    "        img[img<0] = 0\n",
    "        img = img.astype(IINFO.dtype)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def plot(img, resize=1):\n",
    "    img = cv2.resize(img, None, fx = resize, fy=resize)\n",
    "    cv2.imshow('Input', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def plus(a, b):\n",
    "    \n",
    "    assert a.dtype == b.dtype, \"a & b have different types\"\n",
    "    \n",
    "    MAX = np.iinfo(a.dtype).max\n",
    "    \n",
    "    b = MAX - b  # old b is gone shortly after new array is created\n",
    "    np.putmask(a, b < a, b)  # a temp bool array here, then it's gone\n",
    "    a += MAX - b  # a temp array here, then it's gone\n",
    "    \n",
    "    return a\n",
    "\n",
    "def minus(a, b):\n",
    "    \n",
    "    assert a.dtype == b.dtype, \"a & b have different types\"\n",
    "    \n",
    "    min = np.iinfo(a.dtype).min\n",
    "    \n",
    "    b = b + MIN  # old b is gone shortly after new array is created\n",
    "    np.putmask(a, a < b, b)  # a temp bool array here, then it's gone\n",
    "    a -= b - MIN  # a temp array here, then it's gone\n",
    "    \n",
    "    return a\n",
    "    \n",
    "def hist_match(source, template, dtype=None):\n",
    "    \"\"\"\n",
    "    Adjust the pixel values of a grayscale image such that its histogram\n",
    "    matches that of a target image\n",
    "\n",
    "    Arguments:\n",
    "    -----------\n",
    "        source: np.ndarray\n",
    "            Image to transform; the histogram is computed over the flattened\n",
    "            array\n",
    "        template: np.ndarray\n",
    "            Template image; can have different dimensions to source\n",
    "    Returns:\n",
    "    -----------\n",
    "        matched: np.ndarray\n",
    "            The transformed output image\n",
    "    \"\"\"\n",
    "\n",
    "    oldshape = source.shape\n",
    "    source = source.ravel()\n",
    "    template = template.ravel()\n",
    "\n",
    "    # get the set of unique pixel values and their corresponding indices and\n",
    "    # counts\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True, return_counts=True)\n",
    "    t_values, t_counts = np.unique(template, return_counts=True)\n",
    "\n",
    "    # take the cumsum of the counts and normalize by the number of pixels to\n",
    "    # get the empirical cumulative distribution functions for the source and\n",
    "    # template images (maps pixel value --> quantile)\n",
    "    s_quantiles = np.cumsum(s_counts)\n",
    "    s_quantiles = s_quantiles / s_quantiles[-1]\n",
    "    t_quantiles = np.cumsum(t_counts)\n",
    "    t_quantiles = t_quantiles / t_quantiles[-1]\n",
    "\n",
    "    # interpolate linearly to find the pixel values in the template image\n",
    "    # that correspond most closely to the quantiles in the source image\n",
    "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
    "    interp_t_values_reshaped =  interp_t_values[bin_idx].reshape(oldshape)\n",
    "    \n",
    "    # Type conversion\n",
    "    if dtype:\n",
    "        interp_t_values_reshaped = interp_t_values_reshaped.astype(dtype)\n",
    "\n",
    "    return interp_t_values_reshaped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evalutation Function\n",
    "# B = cv2.imread(Bs[3], 0)\n",
    "# B2 = cv2.resize(B, None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)\n",
    "# B3 = cv2.resize(B2, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n",
    "# print(B.shape)\n",
    "# print(B2.shape)\n",
    "# print(B3.shape)\n",
    "# (B == B3).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT Algorithms:\n",
    "# https://www.researchgate.net/publication/272997342_Methods_and_metrics_for_the_assessment_of_Pan-sharpening_algorithms\n",
    "# - PC – Principal Component Spectral Sharpening [7] and [8]\n",
    "# - Gram – Schmidt Spectral Sharpening [9]\n",
    "# - Color Normalized Spectral Sharpening [8], [10]\n",
    "# - DWT – Discrete Wavelet Transform [11] and [12]\n",
    "# - DWTSF – Discrete Wavelet Transform Spatial Frequency [Personnal Addition]\n",
    "# - ATWT – A Trous Wavelet Transform [7], [12] and [13]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bs = glob(\"Landsat/*.tif\")\n",
    "\n",
    "# for i in range(len(Bs)):\n",
    "#     print(i, Bs[i], cv2.imread(Bs[i], -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B1.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B10.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B11.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B2.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B3.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B4.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B5.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B6.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B7.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B8.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_B9.TIF',\n",
       " 'Landsat\\\\LC08_L1TP_199025_20190704_20190718_01_T1_BQA.TIF']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = cv2.resize(cv2.imread(Bs[3], 0), None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)\n",
    "G = cv2.resize(cv2.imread(Bs[4], 0), None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)\n",
    "R = cv2.resize(cv2.imread(Bs[5], 0), None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)\n",
    "PAN = cv2.imread(Bs[9], 0)\n",
    "\n",
    "BGR = np.stack((B, G, R), -1)\n",
    "\n",
    "mask = {\"y1\":2300, \"y2\":2600, \"x1\":4000, \"x2\":4300}\n",
    "\n",
    "BGR = BGR[mask[\"y1\"]:mask[\"y2\"], mask[\"x1\"]:mask[\"x2\"]]\n",
    "PAN = PAN[mask[\"y1\"]:mask[\"y2\"], mask[\"x1\"]:mask[\"x2\"]]\n",
    "\n",
    "plot(\n",
    "    np.hstack((\n",
    "        enhance(BGR, 0.3, 0.3),\n",
    "        enhance(cv2.cvtColor(PAN, cv2.COLOR_GRAY2BGR), 0.3, 0.3),\n",
    "    )), resize=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IHS(BS, PAN, hist_matching=True):\n",
    "    \"\"\"\n",
    "    Method: https://books.google.be/books?id=D7DXAX6eH2oC&pg=PA220&lpg=PA220&dq=pansharpening+IHS+histogram&source=bl&ots=r6PNdsDgZM&sig=ACfU3U3ImkPlQT-RNE3eTQYDABaDeM1LcA&hl=en&sa=X&ved=2ahUKEwi7vfObr-roAhUDNOwKHW4IBe4Q6AEwBHoECAsQKQ#v=onepage&q=pansharpening%20IHS%20histogram&f=false\n",
    "    Image Fusion: Theories, Techniques and Applications - H.B. Mitchell 2010, Springer - PAGE 220: 19.2 IHS Pan-sharpening\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to IHS/HSV color space\n",
    "    HSV = cv2.cvtColor(BS, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Histogram matching before replacing intensity band\n",
    "    if hist_matching:\n",
    "        PAN = hist_match(PAN, HSV[:, :, 2], dtype = PAN.dtype)\n",
    "    \n",
    "    # Replacing intensity band\n",
    "    HSV[:, :, 2] = PAN \n",
    "    \n",
    "    # Revert to original color space\n",
    "    BS_panned = cv2.cvtColor(HSV, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return BS_panned\n",
    "\n",
    "plot(\n",
    "    np.hstack((\n",
    "        enhance(BGR, 0.3, 0.3),\n",
    "        enhance(IHS(BGR, PAN, True), 0.3, 0.3),\n",
    "        enhance(IHS(BGR, PAN, False), 0.3, 0.3),\n",
    "        enhance(cv2.cvtColor(PAN, cv2.COLOR_GRAY2BGR), 0.3, 0.3),\n",
    "    )), resize=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GIHS(BS, PAN, hist_matching=True):\n",
    "    \"\"\"\n",
    "    Method: https://books.google.be/books?id=sXgZBwAAQBAJ&pg=PA134&lpg=PA134&dq=rgb+to+ihs+matrix+multiplication&source=bl&ots=yXcYKuR8te&sig=ACfU3U3w3SysngFj0AwVYyyZ_WRc7KsbTw&hl=fr&sa=X&ved=2ahUKEwj86pWlq-LoAhUPMewKHVZVCxcQ6AEwAXoECAoQAQ#v=onepage&q=rgb%20to%20ihs%20matrix%20multiplication&f=false\n",
    "    Remote Sensing Image Fusion - De Luciano Alparone et al. 2015, CRC Press - PAGE 132-133: 6.2.3.1 Linear IHS\n",
    "    \n",
    "    Also called Brovey\n",
    "    \"\"\"\n",
    "    \n",
    "    # No need to convert IHS/HSV color space - Direct Intensity Band swap\n",
    "    intensity = np.mean(BS, axis=-1, dtype=BS.dtype)\n",
    "    \n",
    "    # Histogram matching before replacing intensity band\n",
    "    if hist_matching:\n",
    "        PAN = hist_match(PAN, intensity, dtype = PAN.dtype)\n",
    "    \n",
    "    # Replacing intensity band - Using custom function to avoid overflow and keep performance high\n",
    "    BS_panned = minus(plus(BS, np.expand_dims(PAN, axis=-1)), np.expand_dims(intensity, axis=-1))\n",
    "    \n",
    "    return BS_panned\n",
    "\n",
    "plot(\n",
    "    np.hstack((\n",
    "        enhance(BGR, 0.3, 0.3),\n",
    "        enhance(GIHS(BGR, PAN, True), 0.3, 0.3),\n",
    "        enhance(GIHS(BGR, PAN, False), 0.3, 0.3),\n",
    "        enhance(cv2.cvtColor(PAN, cv2.COLOR_GRAY2BGR), 0.3, 0.3),\n",
    "    )), resize=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(BS, PAN, hist_matching=True):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshaping into a 1D arrays\n",
    "    BS_reshape = np.reshape(BS, (BS.shape[0] * BS.shape[1], BS.shape[2]))\n",
    "    PAN = np.reshape(PAN, BS.shape[0] * BS.shape[1])\n",
    "\n",
    "    # PCA Decomposition\n",
    "    model = decomposition.PCA(BS.shape[2])\n",
    "    BS_components = model.fit_transform(BS_reshape)\n",
    "\n",
    "    # Histogram matching before replacing first component\n",
    "    if hist_matching:\n",
    "        PAN = hist_match(PAN, \n",
    "                         BS_components[:, 0], \n",
    "                         dtype = BS_components.dtype)\n",
    "\n",
    "    # Replacing the PCA first component\n",
    "    BS_components[:, 0] = PAN\n",
    "\n",
    "    # Invecting PCA\n",
    "    BS_panned = model.inverse_transform(BS_components)\n",
    "\n",
    "    # Reshaping into 2D arrays \n",
    "    BS_panned_reshaped = np.reshape(BS_panned, BS.shape).astype(BS.dtype)\n",
    "    \n",
    "    return BS_panned_reshaped\n",
    "\n",
    "plot(\n",
    "    np.hstack((\n",
    "        enhance(BGR, 0.3, 0.3),\n",
    "        enhance(PCA(BGR, PAN, True), 0.3, 0.3),\n",
    "        enhance(PCA(BGR, PAN, False), 0.3, 0.3),\n",
    "        enhance(cv2.cvtColor(PAN, cv2.COLOR_GRAY2BGR), 0.3, 0.3),\n",
    "    )), resize=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "gs = plt.GridSpec(2, 3)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1], sharex=ax1, sharey=ax1)\n",
    "#ax3 = fig.add_subplot(gs[0, 2], sharex=ax1, sharey=ax1)\n",
    "for aa in (ax1, ax2):\n",
    "    aa.set_axis_off()\n",
    "\n",
    "ax1.imshow(np.mean(BGR, axis=-1), cmap=plt.cm.gray)\n",
    "ax2.imshow(BGR[:, :, 0], cmap=plt.cm.gray)\n",
    "#ax3.imshow(matched, cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the two image\n",
    "B = BGR[:, :, -1].copy()\n",
    "PAN = PAN.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_list():\n",
    "    \n",
    "    print(\"WAVELET TYPE:\")\n",
    "    for family in pywt.families():\n",
    "        print(\"%s family: \" % family + ', '.join(pywt.wavelist(family)))\n",
    "    \n",
    "    print(\"DECOMPOSITION MODES:\")\n",
    "    print(pywt.Modes.modes)\n",
    "    \n",
    "    print(\"FUSION METHOD:\")\n",
    "    print(['min', 'max', 'mean', 'band', 'pan'])\n",
    "       \n",
    "# wavelet_list()\n",
    "wavelet = 'haar' # Wavelet Type\n",
    "mode = 'symmetric' # Decomposition Mode\n",
    "level = None # Number of Decomposition (None = All)\n",
    "fusion = \"mean\" # Fusion method\n",
    "\n",
    "\n",
    "# This function does the coefficient fusing according to the fusion method\n",
    "def coef_fuse(B_coef, PAN_coef, fusion):\n",
    "\n",
    "    if (fusion == 'mean'):\n",
    "        coef = np.average((B_coef, PAN_coef), axis=0)\n",
    "    elif (fusion == 'min'):\n",
    "        coef = np.minimum(B_coef, PAN_coef)\n",
    "    elif (fusion == 'max'):\n",
    "        coef = np.maximum(B_coef, PAN_coef)\n",
    "    elif (fusion == 'band'):\n",
    "        coef = B_coef,\n",
    "    elif (fusion == 'pan'):\n",
    "        coef = PAN_coef\n",
    "    else:\n",
    "        raise ValueError('A very specific bad thing happened.')\n",
    "\n",
    "    return tuple(coef)\n",
    "\n",
    "# Decompose PAN\n",
    "PAN_dec = pywt.wavedec2(data=PAN[:,:], mode=mode, wavelet=wavelet, level=level)\n",
    "\n",
    "# Looping through Bands that needs to be panned\n",
    "if len(BS.shape) == 2:\n",
    "    BS = np.expand_dims(BS, axis=-1)\n",
    "    \n",
    "for Bi in range(BS.shape[-1]):\n",
    "    # Wavelet Decomposition\n",
    "    B_dec = pywt.wavedec2(data=B[:,:,Bi], mode=mode, wavelet=wavelet, level=level)\n",
    "    \n",
    "    # Dropping first empty decomposition\n",
    "    B_dec = B_dec[:-1]\n",
    "    \n",
    "    # Fusing coefficient\n",
    "    coef_fused = [coef_fuse(B_coef, PAN_coef, fusion) for B_coef, PAN_coef in zip(B_dec, PAN_dec)]\n",
    "    \n",
    "    # Inverse Wavelet Tramsformation\n",
    "    img_fused = pywt.waverec2(coef_fused, wavelet)\n",
    "\n",
    "# # Forth: normmalize values to be in uint8\n",
    "# fusedImage = np.multiply(np.divide(img_fused - np.min(img_fused),(np.max(img_fused) - np.min(img_fused))),255)\n",
    "# fusedImage = fusedImage.astype(np.uint8)\n",
    "\n",
    "# # Fith: Show image\n",
    "# cv2.imshow(\"win\",fusedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "from matplotlib import pyplot as plt\n",
    "from pywt._doc_utils import wavedec2_keys, draw_2d_wp_basis\n",
    "\n",
    "x = pywt.data.camera().astype(np.float32)\n",
    "shape = x.shape\n",
    "\n",
    "max_lev = 3       # how many levels of decomposition to draw\n",
    "label_levels = 3  # how many levels to explicitly label on the plots\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=[14, 8])\n",
    "for level in range(0, max_lev + 1):\n",
    "    if level == 0:\n",
    "        # show the original image before decomposition\n",
    "        axes[0, 0].set_axis_off()\n",
    "        axes[1, 0].imshow(x, cmap=plt.cm.gray)\n",
    "        axes[1, 0].set_title('Image')\n",
    "        axes[1, 0].set_axis_off()\n",
    "        continue\n",
    "\n",
    "    # plot subband boundaries of a standard DWT basis\n",
    "    draw_2d_wp_basis(shape, wavedec2_keys(level), ax=axes[0, level],\n",
    "                     label_levels=label_levels)\n",
    "    axes[0, level].set_title('{} level\\ndecomposition'.format(level))\n",
    "\n",
    "    # compute the 2D DWT\n",
    "    c = pywt.wavedec2(x, 'haar', mode='periodization', level=level)\n",
    "    # normalize each coefficient array independently for better visibility\n",
    "    c[0] /= np.abs(c[0]).max()\n",
    "    for detail_level in range(level):\n",
    "        c[detail_level + 1] = [d/np.abs(d).max() for d in c[detail_level + 1]]\n",
    "    # show the normalized coefficients\n",
    "    arr, slices = pywt.coeffs_to_array(c)\n",
    "    axes[1, level].imshow(arr, cmap=plt.cm.gray)\n",
    "    axes[1, level].set_title('Coefficients\\n({} level)'.format(level))\n",
    "    axes[1, level].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
